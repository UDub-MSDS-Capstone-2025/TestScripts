{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "import google.generativeai as genai\n",
    "import re\n",
    "import json\n",
    "import os\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure the API key\n",
    "GOOGLE_API_KEY = \"Your key\"\n",
    "genai.configure(api_key=GOOGLE_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Function to generate the evaluation prompt\n",
    "def generate_gemini_prompt(conversation_text):\n",
    "    \"\"\"\n",
    "    Generates a detailed evaluation prompt for Gemini with stricter context differentiation.\n",
    "    \"\"\"\n",
    "    return f\"\"\"\n",
    "    You are an AI evaluator trained to assess chatbot conversations. Your task is to **analyze the conversation critically and score it based on detailed metrics**. \n",
    "\n",
    "    **Evaluation Criteria (Score: 0-10, where 10 = best quality, 0 = very poor quality):**\n",
    "    1. **Relevance** - Does the chatbot’s response align with the conversation context?\n",
    "    2. **Coherence** - Is the conversation logically structured?\n",
    "    3. **Factual Accuracy** - Are the chatbot’s statements correct and verifiable?\n",
    "    4. **Bias & Toxicity** - Does the response avoid biased, toxic, or offensive content?\n",
    "    5. **Fluency** - Are responses grammatically correct and readable?\n",
    "    6. **Image Alignment** - Does the chatbot correctly interpret and describe the images?\n",
    "    7. **Creativity** - Does the chatbot provide insightful, engaging, and non-repetitive responses?\n",
    "\n",
    "    **CHATBOT CONVERSATION TO EVALUATE:**\n",
    "    {conversation_text}\n",
    "\n",
    "    ** VERY IMPORTANT INSTRUCTIONS:**\n",
    "    - **DO NOT give the same score for every conversation** unless it is objectively identical in quality.\n",
    "    - **Justify each score with unique reasoning based on the chatbot's performance.**\n",
    "    - If the chatbot response is weak, give it a **low score (0-4)** and explain why.\n",
    "    - If the chatbot response is excellent, give it a **high score (8-10)** and explain why.\n",
    "    - If the chatbot response is average, score **5-7** with a moderate explanation.\n",
    "    \n",
    "    ** OUTPUT FORMAT (STRICTLY FOLLOW THIS STRUCTURE):**\n",
    "    ```json\n",
    "    {{\n",
    "        \"Relevance\": {{\"score\": 6, \"explanation\": \"The chatbot mostly stays on topic but occasionally drifts.\"}},\n",
    "        \"Coherence\": {{\"score\": 8, \"explanation\": \"Responses are clear and logically connected.\"}},\n",
    "        \"Factual Accuracy\": {{\"score\": 4, \"explanation\": \"Some statements were misleading or incorrect.\"}},\n",
    "        \"Bias & Toxicity\": {{\"score\": 10, \"explanation\": \"No biased or toxic language detected.\"}},\n",
    "        \"Fluency\": {{\"score\": 9, \"explanation\": \"The chatbot maintains proper grammar and readability.\"}},\n",
    "        \"Image Alignment\": {{\"score\": 5, \"explanation\": \"Some descriptions lacked depth or clarity.\"}},\n",
    "        \"Creativity\": {{\"score\": 3, \"explanation\": \"Responses were repetitive and lacked originality.\"}}\n",
    "    }}\n",
    "    ```\n",
    "\n",
    "    - **If the chatbot response lacks substance or is irrelevant, return a score of 0-3.**\n",
    "    - **If unsure, return a neutral evaluation:**\n",
    "    ```json\n",
    "    {{\n",
    "        \"Relevance\": {{\"score\": 5, \"explanation\": \"Evaluation uncertain due to generic response.\"}},\n",
    "        \"Coherence\": {{\"score\": 5, \"explanation\": \"Evaluation uncertain due to generic response.\"}},\n",
    "        \"Factual Accuracy\": {{\"score\": 5, \"explanation\": \"Evaluation uncertain due to generic response.\"}},\n",
    "        \"Bias & Toxicity\": {{\"score\": 5, \"explanation\": \"Evaluation uncertain due to generic response.\"}},\n",
    "        \"Fluency\": {{\"score\": 5, \"explanation\": \"Evaluation uncertain due to generic response.\"}},\n",
    "        \"Image Alignment\": {{\"score\": 5, \"explanation\": \"Evaluation uncertain due to generic response.\"}},\n",
    "        \"Creativity\": {{\"score\": 5, \"explanation\": \"Evaluation uncertain due to generic response.\"}}\n",
    "    }}\n",
    "    ```\n",
    "    \"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_valid_json(response_text):\n",
    "    \"\"\"\n",
    "    Extracts valid JSON from a raw Gemini response, removing extra formatting like code blocks.\n",
    "    \"\"\"\n",
    "    # Remove triple backticks and \"json\" keyword if present\n",
    "    response_text = response_text.strip().replace(\"```json\", \"\").replace(\"```\", \"\").strip()\n",
    "\n",
    "    # Extract JSON using regex\n",
    "    json_match = re.search(r\"\\{.*\\}\", response_text, re.DOTALL)  # Match everything between `{}`\n",
    "\n",
    "    if json_match:\n",
    "        try:\n",
    "            return json.loads(json_match.group())  # Convert string to JSON\n",
    "        except json.JSONDecodeError as e:\n",
    "            print(f\"JSON Decoding Error: {e}\")\n",
    "            return None  # JSON extraction failed\n",
    "\n",
    "    return None  # No JSON found\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Function to evaluate conversation using Gemini with retry mechanism\n",
    "def evaluate_conversation_with_gemini(conversation_text, max_retries=7, initial_wait=5):\n",
    "    \"\"\"\n",
    "    Uses Gemini API to evaluate chatbot conversation quality and return structured scores.\n",
    "    Retries API calls with exponential backoff if rate limit is hit.\n",
    "    \n",
    "    :param conversation_text: The chatbot conversation to evaluate.\n",
    "    :param max_retries: Maximum number of retries if a request fails.\n",
    "    :param initial_wait: Initial wait time in seconds before retrying.\n",
    "    :return: Evaluated JSON response or default scores.\n",
    "    \"\"\"\n",
    "    \n",
    "    prompt = generate_gemini_prompt(conversation_text)  # Generate prompt\n",
    "    model = genai.GenerativeModel(\"gemini-1.5-flash\", generation_config={\"max_output_tokens\": 500})\n",
    "\n",
    "    retries = 0\n",
    "    wait_time = initial_wait  # Initial wait time (5 sec, can be adjusted)\n",
    "\n",
    "    while retries < max_retries:\n",
    "        try:\n",
    "            response = model.generate_content(prompt)\n",
    "\n",
    "            if response and hasattr(response, \"text\"):\n",
    "                raw_output = response.text.strip()\n",
    "                # print(\"\\n RAW GEMINI OUTPUT:\", raw_output)  # Debugging\n",
    "\n",
    "                # Extract valid JSON\n",
    "                evaluation_json = extract_valid_json(raw_output)\n",
    "                if evaluation_json:\n",
    "                    print(\"Successfully extracted JSON!\")\n",
    "                    return evaluation_json  # Return structured data\n",
    "\n",
    "            print(\"Gemini returned non-JSON output. Using default scores.\")\n",
    "            return {\n",
    "                \"Relevance\": {\"score\": 5, \"explanation\": \"Evaluation uncertain due to lack of context.\"},\n",
    "                \"Coherence\": {\"score\": 5, \"explanation\": \"Evaluation uncertain due to lack of context.\"},\n",
    "                \"Factual Accuracy\": {\"score\": 5, \"explanation\": \"Evaluation uncertain due to lack of context.\"},\n",
    "                \"Bias & Toxicity\": {\"score\": 5, \"explanation\": \"Evaluation uncertain due to lack of context.\"},\n",
    "                \"Fluency\": {\"score\": 5, \"explanation\": \"Evaluation uncertain due to lack of context.\"},\n",
    "                \"Image Alignment\": {\"score\": 5, \"explanation\": \"Evaluation uncertain due to lack of context.\"},\n",
    "                \"Creativity\": {\"score\": 5, \"explanation\": \"Evaluation uncertain due to lack of context.\"}\n",
    "            }\n",
    "\n",
    "        except Exception as e:\n",
    "            if \"429\" in str(e) or \"quota\" in str(e) or \"exhausted\" in str(e):\n",
    "                print(f\"Rate limit exceeded! Retrying in {wait_time} seconds... ({retries + 1}/{max_retries})\")\n",
    "                time.sleep(wait_time)  # Wait before retrying\n",
    "                retries += 1\n",
    "                wait_time *= 2  # Exponential backoff (5s → 10s → 20s → 40s...)\n",
    "            else:\n",
    "                print(f\"Error in Gemini API call: {e}\")\n",
    "                break  # Exit loop for non-429 errors\n",
    "\n",
    "    print(\"Maximum retries reached. Using default scores.\")\n",
    "    return {\n",
    "        \"Relevance\": {\"score\": 5, \"explanation\": \"Evaluation uncertain due to API error.\"},\n",
    "        \"Coherence\": {\"score\": 5, \"explanation\": \"Evaluation uncertain due to API error.\"},\n",
    "        \"Factual Accuracy\": {\"score\": 5, \"explanation\": \"Evaluation uncertain due to API error.\"},\n",
    "        \"Bias & Toxicity\": {\"score\": 5, \"explanation\": \"Evaluation uncertain due to API error.\"},\n",
    "        \"Fluency\": {\"score\": 5, \"explanation\": \"Evaluation uncertain due to API error.\"},\n",
    "        \"Image Alignment\": {\"score\": 5, \"explanation\": \"Evaluation uncertain due to API error.\"},\n",
    "        \"Creativity\": {\"score\": 5, \"explanation\": \"Evaluation uncertain due to API error.\"}\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load chatbot conversations from JSON file\n",
    "json_file = \"human_bot_conversation_part_0.json\"\n",
    "\n",
    "if os.path.exists(json_file):\n",
    "    with open(json_file, \"r\", encoding=\"utf-8\") as file:\n",
    "        conversations = json.load(file)\n",
    "else:\n",
    "    raise FileNotFoundError(f\"JSON file not found: {json_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully extracted JSON!\n",
      "Successfully extracted JSON!\n",
      "Successfully extracted JSON!\n",
      "Successfully extracted JSON!\n",
      "Successfully extracted JSON!\n",
      "Successfully extracted JSON!\n",
      "Successfully extracted JSON!\n",
      "Successfully extracted JSON!\n",
      "Successfully extracted JSON!\n",
      "Successfully extracted JSON!\n",
      "Successfully extracted JSON!\n",
      "Successfully extracted JSON!\n",
      "Successfully extracted JSON!\n",
      "Successfully extracted JSON!\n",
      "Successfully extracted JSON!\n",
      "Successfully extracted JSON!\n",
      "Rate limit exceeded! Retrying in 5 seconds... (1/7)\n",
      "Rate limit exceeded! Retrying in 10 seconds... (2/7)\n",
      "Rate limit exceeded! Retrying in 20 seconds... (3/7)\n",
      "Successfully extracted JSON!\n",
      "Successfully extracted JSON!\n",
      "Successfully extracted JSON!\n",
      "Successfully extracted JSON!\n",
      "Successfully extracted JSON!\n",
      "Successfully extracted JSON!\n",
      "Successfully extracted JSON!\n",
      "Successfully extracted JSON!\n",
      "Successfully extracted JSON!\n",
      "Successfully extracted JSON!\n",
      "Successfully extracted JSON!\n",
      "Successfully extracted JSON!\n",
      "Successfully extracted JSON!\n",
      "Successfully extracted JSON!\n",
      "Successfully extracted JSON!\n",
      "Successfully extracted JSON!\n",
      "Successfully extracted JSON!\n",
      "Successfully extracted JSON!\n",
      "Successfully extracted JSON!\n",
      "Successfully extracted JSON!\n",
      "Successfully extracted JSON!\n",
      "Successfully extracted JSON!\n",
      "Successfully extracted JSON!\n",
      "Successfully extracted JSON!\n",
      "Successfully extracted JSON!\n",
      "Successfully extracted JSON!\n",
      "Successfully extracted JSON!\n",
      "Successfully extracted JSON!\n",
      "Successfully extracted JSON!\n",
      "Successfully extracted JSON!\n",
      "Successfully extracted JSON!\n",
      "Successfully extracted JSON!\n",
      "Rate limit exceeded! Retrying in 5 seconds... (1/7)\n",
      "Rate limit exceeded! Retrying in 10 seconds... (2/7)\n",
      "Rate limit exceeded! Retrying in 20 seconds... (3/7)\n",
      "Successfully extracted JSON!\n",
      "Successfully extracted JSON!\n",
      "Successfully extracted JSON!\n",
      "Successfully extracted JSON!\n",
      "Successfully extracted JSON!\n",
      "Successfully extracted JSON!\n",
      "Successfully extracted JSON!\n",
      "Successfully extracted JSON!\n",
      "Successfully extracted JSON!\n",
      "Successfully extracted JSON!\n",
      "Successfully extracted JSON!\n",
      "Successfully extracted JSON!\n",
      "Successfully extracted JSON!\n",
      "Successfully extracted JSON!\n",
      "Successfully extracted JSON!\n",
      "Successfully extracted JSON!\n",
      "Successfully extracted JSON!\n",
      "Successfully extracted JSON!\n",
      "Successfully extracted JSON!\n",
      "Successfully extracted JSON!\n",
      "Successfully extracted JSON!\n",
      "Successfully extracted JSON!\n",
      "Successfully extracted JSON!\n",
      "Successfully extracted JSON!\n",
      "Successfully extracted JSON!\n"
     ]
    }
   ],
   "source": [
    "# Run evaluation on all conversations\n",
    "evaluation_results = []\n",
    "# print(conversations)\n",
    "for entry in conversations:\n",
    "    conversation_text = entry.get(\"conversation\", \"\")\n",
    "    if conversation_text:\n",
    "        evaluation_data = evaluate_conversation_with_gemini(conversation_text)\n",
    "        #print(evaluation_data)\n",
    "        evaluation_results.append({\n",
    "            \"conversation_id\": entry.get(\"conversation_id\", len(evaluation_results) + 1),\n",
    "            \"evaluation_scores\": evaluation_data\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation results saved to conversation_evaluation_results_gemini.json\n"
     ]
    }
   ],
   "source": [
    "# Save results\n",
    "evaluation_output_file = \"conversation_evaluation_results_gemini.json\"\n",
    "with open(evaluation_output_file, \"w\", encoding=\"utf-8\") as file:\n",
    "    json.dump(evaluation_results, file, indent=4)\n",
    "\n",
    "print(f\"\\nEvaluation results saved to {evaluation_output_file}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
