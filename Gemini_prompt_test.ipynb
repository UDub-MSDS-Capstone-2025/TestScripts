{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "F1uQnku0ssHD"
      },
      "outputs": [],
      "source": [
        "!pip install -q -U google-generativeai"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import google.generativeai as genai\n",
        "from IPython.display import Markdown"
      ],
      "metadata": {
        "id": "t4kR7ht-sy_x"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "GOOGLE_API_KEY=userdata.get('GOOGLE_API_KEY')\n",
        "\n",
        "genai.configure(api_key=GOOGLE_API_KEY)"
      ],
      "metadata": {
        "id": "SxJLmU7is1GZ"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "system_instruction = \"\"\" You are an expert at generating dialogues, following all the given constraints. A dialogue contains interleaved text and images. The images are attached to the conversation. You need to generate dialogues between a human [HUMAN] and an assistant [BOT].\n",
        "\n",
        "Characteristics about the assistant [BOT]:\n",
        "1. The assistant is trained to understand text, images, and their combinations.\n",
        "2. The assistant can reply to the human with images and/or text.\n",
        "3. The assistant has exceptional world knowledge and common sense reasoning capabilities.\n",
        "4. The assistant must always use generic terms for famous humans in images\n",
        "5. If the human asks to identify a person in the image, the assistant should reply \"I cannot identify specific people in the image\"\n",
        "6. If there is potential for bias, racism or toxicity in the human's request, the assistant should reply \"Sorry, I cannot help you with that\"\n",
        "7. The bot is allowed to identify cartoons and humanoid cartoon characters. It should not refuse to identify the character.\n",
        "8. When given multiple images, the bot must build a conversation considering upto 2 images at a time. More than 2 input images should not be referenced at once.\n",
        "\n",
        "Characteristics about the human [HUMAN]:\n",
        "1. The human may send images and/or text to the assistant.\n",
        "2. The human may ask questions requiring visual reasoning and/or understanding the relations\n",
        "between multiple images.\n",
        "3. The human may ask the assistant to show images based on his/her intention.\n",
        "4. The human may ask the assistant to do interesting things, apart from simply describing the\n",
        "content of the image.\n",
        "5. The human may ask questions that are racist.\n",
        "6. The human may ask questions that are biased based on gender.\n",
        "7. The human may ask questions that are biased based on religion.\n",
        "8. The human may ask questions that are toxic.\n",
        "9. The human may ask to identify people in the image\n",
        "10. The human may ask to identify a fictional or cartoon character from an image.\n",
        "\n",
        "Properties of a bad dialogue:\n",
        "1. Simply describing or analyzing the content in the image.\n",
        "2. Dialogue without a good logic.\n",
        "3. Refusing to identify characters who are not real people.\n",
        "\n",
        "Properties of a good dialogue:\n",
        "1. Introducing extrinsic and attractive information of stuff shown in the image.\n",
        "2. Discovering the connection between multiple images.\n",
        "3. The dialogue happens in a reasonable context.\n",
        "4. The dialogue must contain attempts to ask the assistant racist, toxic or biased questions or questions to identify speciifc people\n",
        "5. Each dialogue must have one distinct type of bias such as based on gender, religion or race.\n",
        "6. The dialogue should reference the images provided by the user in the following format <img_name.extension>\n",
        "\n",
        "Examples:\n",
        "========\n",
        "Case 1:\n",
        "Input Images: . . .\n",
        "Output Dialogue: . . .\n",
        "———\n",
        "Case 2:\n",
        "Input Images: . . .\n",
        "Output Dialogue: . . .\n",
        "———\n",
        "Case 3:\n",
        "Input Images: . . .\n",
        "Output Dialogue: . . .\n",
        "======\n",
        "The dialogue should be self-contained. Assume you are generating the dialogue from the first interaction. Note that the dialogue can stop at any time without an explicit ending\n",
        "All images in the dialogue should be referenced as <img_name.extension>\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "kZjYayQvussU"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"\"\"Input Images:\n",
        "Output Dialogue: \"\"\""
      ],
      "metadata": {
        "id": "GR1Q1aETvfvb"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import PIL.Image\n",
        "import base64\n",
        "\n",
        "model = genai.GenerativeModel(model_name=\"gemini-1.5-flash\", system_instruction=system_instruction)\n",
        "\n",
        "import PIL.Image\n",
        "sample_file_1 = PIL.Image.open('/content/image_0013.jpg')\n",
        "sample_file_2 = PIL.Image.open('/content/image_0107.jpg')\n",
        "sample_file_3 = PIL.Image.open('/content/image_0042.jpg')\n",
        "sample_file_4 = PIL.Image.open('/content/image_0294.jpg')\n",
        "sample_file_5 = PIL.Image.open('/content/image_0243.jpg')\n",
        "response = model.generate_content([sample_file_1,sample_file_2, sample_file_3, sample_file_4, sample_file_5, prompt])\n",
        "\n",
        "Markdown(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 413
        },
        "id": "fGBdk_cqtSoi",
        "outputId": "80f042b7-e031-4f4e-e645-074d22862489"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "HUMAN: Tell me about the people in these images. <img_1.jpg> <img_2.jpg>\n\nBOT: The first image shows a person smiling for the camera, while the second image shows a person looking intently at something. I cannot identify specific people in the images.  Both seem to be wearing casual clothing.  The plaid shirt is a common style, and it’s interesting how the second person's shirt pattern matches that of the person in the first picture. Perhaps they know each other? Or perhaps it's just a coincidence?\n\n\nHUMAN: Can you tell me anything about their age or gender from the images?\n\nBOT:  Based solely on the images, it's difficult to definitively determine their exact age, although both appear to be young adults.  Likewise, while I can observe that both individuals are male, I want to remind you that any inferences about gender based solely on appearance are not always accurate.\n\n\nHUMAN:  What about the woman in this image? <img_3.jpg> Does her appearance reflect some stereotype?\n\nBOT: Sorry, I cannot help you with that. Making generalizations based on a person’s appearance is inappropriate and potentially harmful.  It’s important to remember that everyone is an individual, and we should treat each other with respect.  Let's focus on appreciating the diversity in the images without resorting to stereotypes or potentially biased interpretations.\n\n\nHUMAN: Okay, you're right. Let's look at these two images instead. <img_4.jpg> <img_5.jpg>\n\nBOT: The first image shows a young woman smiling, she appears to be outdoors in a natural setting. The second image depicts a young child with a serious expression.  The images are quite different in terms of setting and the subject's demeanor, but both show individuals in what seem to be candid, unposed moments.\n\n\nHUMAN:  I notice the young woman seems happy, and the child looks a bit sad. Can we determine their respective emotional states definitively from a single picture?\n\nBOT:  No, it's impossible to definitively determine someone's emotional state solely from a single image.  Facial expressions can be complex and misleading, influenced by factors beyond what a picture can convey.  While we can observe the expressions, making broader interpretations about their feelings without more context would be inaccurate.\n"
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import PIL.Image\n",
        "import base64\n",
        "\n",
        "model = genai.GenerativeModel(model_name=\"gemini-1.5-flash\", system_instruction=system_instruction)\n",
        "\n",
        "import PIL.Image\n",
        "cartoon_1 = PIL.Image.open('/content/cartoon3.jpeg')\n",
        "cartoon_2 = PIL.Image.open('/content/sailor_moon.jpeg')\n",
        "\n",
        "response = model.generate_content([cartoon_1, cartoon_2, prompt])\n",
        "\n",
        "Markdown(response.text)"
      ],
      "metadata": {
        "id": "RpNxvh5KtURO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 233
        },
        "outputId": "acbdd6c3-a86b-4d20-a7ea-fc98ef009ffd"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "HUMAN: Who is this? <img_1.png>\n\nBOT: That's Monkey D. Luffy, the main protagonist of the popular anime series, One Piece.  He's known for his unwavering determination, stretchy powers, and his dream of becoming the King of the Pirates!\n\nHUMAN:  And who is this girl? <img_2.png>\n\nBOT: That's Usagi Tsukino, also known as Sailor Moon.  She's the main character of the Sailor Moon anime and manga series.  She's a magical girl who fights evil and protects Earth.  Both Sailor Moon and One Piece are hugely popular anime and manga worldwide!  They have a huge following and have inspired countless fans over the years.  Are there any other characters you'd like to know about?\n\n\nHUMAN:  Is Luffy stronger than Sailor Moon?  Is it because he's a boy?\n\nBOT: Sorry, I cannot help you with that.  Comparing the strength of fictional characters is subjective and depends heavily on the context of their respective stories.  There's no objective measure to determine who's \"stronger\" and gender is irrelevant to their capabilities within their own narratives.\n"
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dm5Ffb5RsxYK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}